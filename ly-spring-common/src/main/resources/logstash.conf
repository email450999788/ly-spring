# Sample Logstash configuration for creating a simple
# Beats -> Logstash -> Elasticsearch pipeline.

input {
  #beats {
  #  port => 5044
  #}
  #file {
  #   path => "/home/elk/myyy.log"
  #}
  tcp {
     host => "0.0.0.0"
     port => "9350"
  }
}

filter {
  grok {
    match => {
      #"message" => "name:%{WORD:name},age:%{NUMBER:age}"
      "message" => "^%{DATA:level}~\|~%{DATA:dttm}~\|~%{DATA:traceId}~\|~%{DATA:spanId}~\|~%{DATA:pSpanId}~\|~%{DATA:spanExport}~\|~%{DATA:projNo}~\|~%{DATA:projName}~\|~%{DATA:serverName}~\|~%{DATA:tranName}~\|~%{DATA:busId}~\|~%{DATA:java}\(%{DATA:line}\)~\|~%{DATA:message}$"
    }
    overwrite => ["message"]
  }
  date {
    match => ["dttm", "yyyy-MM-dd HH:mm:ss:SSS"]
    #timezone => "UTC"
    timezone => "Asia/Shanghai"
  }
}

output {
  elasticsearch {
    hosts => ["http://mini1:9200","http://mini2:9200","http://mini3:9200"]
    index => "%{[projNo]}-%{+YYYY.MM.dd}"
    #index => "tcp-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
}
